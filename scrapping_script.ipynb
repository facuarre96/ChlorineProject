{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+Ncze3ruKSR+BgXKpsE/S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/facuarre96/ChlorineProject/blob/main/scrapping_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9xTHXdeRi-e"
      },
      "outputs": [],
      "source": [
        "#set up + import\n",
        "!pip install pandas openpyxl requests beautifulsoup4 PyMuPDF\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import html\n",
        "import fitz\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#more set up + import\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path2 = '/content/drive/MyDrive/1-s2.0-S027323002200174X-mmc2.xlsx'\n",
        "df1 = pd.read_excel(file_path2)\n",
        "\n",
        "file_path3 = '/content/drive/MyDrive/1-s2.0-S027323002200174X-mmc3.xlsx'\n",
        "df2 = pd.read_excel(file_path3)"
      ],
      "metadata": {
        "id": "jL2KQuPARmJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test acsess\n",
        "print(df1.head())\n",
        "print(df2.head())"
      ],
      "metadata": {
        "id": "Z3TwyovORoK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_abstract(url):\n",
        "    # URL needs DOI or not\n",
        "    if not url.startswith('http'):\n",
        "        url = 'https://doi.org/' + url\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, allow_redirects=True, timeout=30)  # Increased timeout\n",
        "        response.raise_for_status()\n",
        "\n",
        "        content_type = response.headers.get('Content-Type', '').lower()\n",
        "\n",
        "        if content_type.startswith('application/pdf'):\n",
        "            # Skip PDFs and return None\n",
        "            return None, False\n",
        "        elif content_type.startswith('text/html'):\n",
        "            # Extract text from HTML content\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # find the abstract using common patterns\n",
        "            abstract = None\n",
        "\n",
        "            # Check for common tags and classes/ids\n",
        "            possible_selectors = [\n",
        "                {'name': 'div', 'class_': 'abstract'},  # Example: <div class=\"abstract\">\n",
        "                {'name': 'section', 'class_': 'abstract'},  # Example: <section class=\"abstract\">\n",
        "                {'name': 'p', 'class_': 'abstract'},  # Example: <p class=\"abstract\">\n",
        "                {'name': 'div', 'id': 'abstract'},  # Example: <div id=\"abstract\">\n",
        "                {'name': 'section', 'id': 'abstract'},  # Example: <section id=\"abstract\">\n",
        "                {'name': 'p', 'id': 'abstract'},  # Example: <p id=\"abstract\">\n",
        "                {'name': 'div', 'class_': 'summary'},  # Example: <div class=\"summary\">\n",
        "                {'name': 'section', 'class_': 'summary'},  # Example: <section class=\"summary\">\n",
        "                {'name': 'p', 'class_': 'summary'},  # Example: <p class=\"summary\">\n",
        "                {'name': 'div', 'id': 'summary'},  # Example: <div id=\"summary\">\n",
        "                {'name': 'section', 'id': 'summary'},  # Example: <section id=\"summary\">\n",
        "                {'name': 'p', 'id': 'summary'},  # Example: <p id=\"summary\">\n",
        "                {'name': 'div', 'class_': 'overview'},  # Example: <div class=\"overview\">\n",
        "                {'name': 'section', 'class_': 'overview'},  # Example: <section class=\"overview\">\n",
        "                {'name': 'p', 'class_': 'overview'},  # Example: <p class=\"overview\">\n",
        "                {'name': 'div', 'id': 'overview'},  # Example: <div id=\"overview\">\n",
        "                {'name': 'section', 'id': 'overview'},  # Example: <section id=\"overview\">\n",
        "                {'name': 'p', 'id': 'overview'},  # Example: <p id=\"overview\">\n",
        "                {'name': 'div', 'class_': 'conclusion'},  # Example: <div class=\"conclusion\">\n",
        "                {'name': 'section', 'class_': 'conclusion'},  # Example: <section class=\"conclusion\">\n",
        "                {'name': 'p', 'class_': 'conclusion'},  # Example: <p class=\"conclusion\">\n",
        "                {'name': 'div', 'id': 'conclusion'},  # Example: <div id=\"conclusion\">\n",
        "                {'name': 'section', 'id': 'conclusion'},  # Example: <section id=\"conclusion\">\n",
        "                {'name': 'p', 'id': 'conclusion'},  # Example: <p id=\"conclusion\">\n",
        "                {'name': 'div', 'class_': 'highlights'},  # Example: <div class=\"highlights\">\n",
        "                {'name': 'section', 'class_': 'highlights'},  # Example: <section class=\"highlights\">\n",
        "                {'name': 'p', 'class_': 'highlights'},  # Example: <p class=\"highlights\">\n",
        "                {'name': 'div', 'id': 'highlights'},  # Example: <div id=\"highlights\">\n",
        "                {'name': 'section', 'id': 'highlights'},  # Example: <section id=\"highlights\">\n",
        "                {'name': 'p', 'id': 'highlights'},  # Example: <p id=\"highlights\">\n",
        "                {'name': 'div', 'class_': 'executive-summary'},  # Example: <div class=\"executive-summary\">\n",
        "                {'name': 'section', 'class_': 'executive-summary'},  # Example: <section class=\"executive-summary\">\n",
        "                {'name': 'p', 'class_': 'executive-summary'},  # Example: <p class=\"executive-summary\">\n",
        "                {'name': 'div', 'id': 'executive-summary'},  # Example: <div id=\"executive-summary\">\n",
        "                {'name': 'section', 'id': 'executive-summary'},  # Example: <section id=\"executive-summary\">\n",
        "                {'name': 'p', 'id': 'executive-summary'},  # Example: <p id=\"executive-summary\">\n",
        "                {'name': 'div', 'class_': 'c-article-section__content', 'id': 'Abs1-content'},  # Example: <div class=\"c-article-section__content\" id=\"Abs1-content\">\n",
        "            ]\n",
        "\n",
        "            for selector in possible_selectors:\n",
        "                abstract_tag = soup.find(selector['name'], class_=selector.get('class_'), id=selector.get('id'))\n",
        "                if abstract_tag:\n",
        "                    abstract = ' '.join(abstract_tag.stripped_strings)  # Join all the strings in the tag, handling nested tags\n",
        "                    break\n",
        "\n",
        "            if abstract:\n",
        "                return html.unescape(abstract), True  # Unescape HTML entities\n",
        "            else:\n",
        "                # Fallback: Try to find an abstract within meta tags (common in some articles)\n",
        "                meta_abstract = soup.find('meta', attrs={'name': 'description'})\n",
        "                if meta_abstract and meta_abstract.get('content'):\n",
        "                    return html.unescape(meta_abstract['content']), True\n",
        "\n",
        "                return None, True\n",
        "        else:\n",
        "            return None, False\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return None, False\n",
        "\n",
        "def process_row(index, row):\n",
        "    url = row['url']\n",
        "    abstract = row['abstract']\n",
        "\n",
        "    # Skip URLs that are empty, NaN, or contain \"Internal Retrieval\"\n",
        "    if pd.isna(url) or not url or 'Internal Retrieval' in url:\n",
        "        return None\n",
        "\n",
        "    result = {\n",
        "        'index': index,\n",
        "        'url': url,\n",
        "        'abstract': None,\n",
        "        'is_html': False,\n",
        "    }\n",
        "    if abstract and not pd.isna(abstract):  # Check if 'abstract' is not empty\n",
        "        fetched_abstract, is_html = fetch_abstract(url)\n",
        "        if fetched_abstract:  # Only count if an actual abstract is returned\n",
        "            result['abstract'] = fetched_abstract\n",
        "        result['is_html'] = is_html\n",
        "    return result\n",
        "\n",
        "total = 0\n",
        "abstracts_fetched = 0\n",
        "urls_opened = 0\n",
        "htmls_opened = 0\n",
        "\n",
        "results = []\n",
        "\n",
        "# Using ThreadPoolExecutor for concurrent requests\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    futures = [executor.submit(process_row, index, row) for index, row in df1.iterrows()]\n",
        "    for future in as_completed(futures):\n",
        "        result = future.result()\n",
        "        if result is None:\n",
        "            continue  # Skip this result if it was filtered out\n",
        "        total += 1\n",
        "        if result['abstract']:\n",
        "            abstracts_fetched += 1\n",
        "            print(f\"URL: {result['url']}\")\n",
        "            print(f\"Abstract: {result['abstract']}\")\n",
        "            print()\n",
        "        if result['is_html']:\n",
        "            htmls_opened += 1\n",
        "            print(f\"URL: {result['url']}\")\n",
        "            print()\n",
        "        if result['url']:\n",
        "            urls_opened += 1\n",
        "\n",
        "print(\"Total iterations:\", total)\n",
        "print()\n",
        "print(\"Abstracts fetched:\", abstracts_fetched)\n",
        "print()\n",
        "print(\"URLs opened:\", urls_opened)\n",
        "print()\n",
        "print(\"HTML pages opened:\", htmls_opened)"
      ],
      "metadata": {
        "id": "FVhNY7eHRpzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.0\n",
        "import openai"
      ],
      "metadata": {
        "id": "BnTyccz2SGWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'X'"
      ],
      "metadata": {
        "id": "qSJSri_ASKCG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}